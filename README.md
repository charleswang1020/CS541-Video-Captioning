# CS541-2019S-Video Captioning
WPI CS 541 Deep Learning Project 

## Description of the project
The accurate automated captioning videos is an important task for both making video collection more accessible to human users and for making video content more accessible to the visually impaired. This task can be segmented into two subtasks: audio encoding into language and visual encoding into language. In this study we focus on the task of expressing the visual content of the videos in the English language. One of the more common frameworks for attempting this task is an encoder-decoder framework. We use this framework to implement and train from scratch a video captioning RNN (GAN) to investigate a current state of the art technique. To improve the performance of the technique we experiment with augmenting this approach with some of the newest pre-trained CNN models for our initial image feature extraction and use modern regularization methods. To demonstrate the effectiveness of our approach we test our method on the MSR-VTT dataset.
